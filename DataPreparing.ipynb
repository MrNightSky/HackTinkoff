{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from pymystem3 import Mystem\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "model = api.load(\"word2vec-ruscorpora-300\")  # download the model and return as object ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    if(s == ' '):\n",
    "        return False\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def preprocess_text(str1):\n",
    "    \n",
    "    mystem = Mystem()\n",
    "    tokens = mystem.lemmatize(str1.lower())\n",
    "    str1 = \" \".join(tokens)\n",
    "    \n",
    "    words = []\n",
    "    for word in str1.split():\n",
    "        if (word.isalpha()) and (not isEnglish(word)):\n",
    "            words.append(word)\n",
    "    \n",
    "    res = set()\n",
    "    for word in words:\n",
    "        word_adv=word+'_ADJ'\n",
    "        word_noun=word+'_NOUN'\n",
    "        try:\n",
    "            model.similarity(word_adv, 'слово_NOUN')\n",
    "            res.add(word_adv)\n",
    "        except BaseException:\n",
    "            try:\n",
    "                model.similarity(word_noun, 'слово_NOUN')\n",
    "                res.add(word_noun)\n",
    "            except BaseException:\n",
    "                pass\n",
    "    ans = ''\n",
    "    for word in list(res):\n",
    "        ans += word\n",
    "        ans += ','\n",
    "    return ans[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chdir(path):\n",
    "    os.chdir('D:\\Мой диск\\Pr\\Py\\Challenges\\hackProf\\HackTinkoff\\data\\\\' + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_create(path):\n",
    "    chdir(path)\n",
    "    data = pd.read_excel('data_cleaned.xls')\n",
    "    data['words'] = pd.Series(np.zeros(data.shape[0]))\n",
    "    for i in tqdm.tqdm_notebook(range(N)):\n",
    "        data['words'][i] = preprocess_text(data['Название'][i])\n",
    "    data.to_csv('new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['food\\\\abrikos', 'food\\\\auchan', 'food\\\\foodband', 'food\\\\iherb.com', 'sport\\\\double-sports',\n",
    "        'sport\\\\gold-standart.com', 'sport\\\\iherb.com', 'sport\\\\pro-bike', 'sport\\\\tramontana.ru']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    data_create(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
